{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 支持向量机\n",
    "支持向量机（support vector machine）是一种二类分类模型。它的基本模型时定义在特征空间上的间隔最大的线性分类器，间隔最大使它有别于感知机。支持向量机还包括核技巧，这使它成为实质上的非线性分类器。支持向量机的学习策略是间隔最大化，可形式化为一个求解凸二次规划（convex quadratic programming）的问题，也等价于正则化的合页损失函数的最小问题。\n",
    "Cortes与Vapnik提出线性支持向量机，Boser、Guyon与Vapnik又引入核技巧，提出非线性支持向量机。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性可分支持向量机与硬间隔最大化\n",
    "感知机利用误分类最小策略求分离超平面，存在无穷多个解。\n",
    "线性可分支持向量机利用间隔最大化求解最优分离超平面，解唯一。\n",
    "### 线性可分支持向量机\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给定线性可分训练数据集，通过间隔最大化或等价的求解对应的凸二次规划问题学习得到的分离超平面为\n",
    "$$\n",
    "w^*\\cdot x+b^*=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以及相应的分类决策函数\n",
    "$$\n",
    "f(x)=sign(w^*\\cdot x+b^*)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**函数间隔**\n",
    "对于给定的训练数据集T与超平面(w,b)，定义超平面(w,b)关于样本点（x_i,y_i）的函数间隔为\n",
    "$$\n",
    "\\hat{\\gamma}_i=y_i(w_i\\cdot x_i +b)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义$\\hat{\\gamma}$为关于所有样本点中的最小值\n",
    "$$\n",
    "\\hat{\\gamma}=\\min_{i=1,\\ldots,N}\\gamma_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**几何间隔 geometric margin**\n",
    "通过规范化法向量$w$，使得$||w||=1$,这时函数间隔称为几何间隔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大化间隔问题可写为\n",
    "$$\n",
    "\\max_{w,b} \\frac{\\hat \\gamma}{||w||} \\\\\n",
    "s.t. \\ y_i(w_i\\cdot x_i+b) \\ge \\hat{\\gamma}, i=1,2,\\ldots,N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "等价于凸二次规划\n",
    "$$\n",
    "\\min_{w,b} \\frac{1}{2}||w||^2 \\\\\n",
    "s.t. y_i(w \\cdot x_i+b)-1 \\ge 0, i=1,2,\\ldots,N\n",
    "$$\n",
    "最大间隔分离超平面存在且唯一"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 相关定义\n",
    "### 仿射函数\n",
    "$f(x)$称为仿射函数，如果它满足$f(x)=a\\cdot x+b,a \\in R^n, b \\in R, x\\in R^n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 凸优化\n",
    "凸优化问题是指约束最优化问题\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "\\min_{w}f(w) \\\\\n",
    "s.t. g_i(w) & \\le & 0 , i=1,2,\\ldots,k \\\\\n",
    "h_i(w) & = & 0 , i=1,2,\\ldots,l\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "其中，目标函数$f(w)$和约束函数$g_i(w)$都是$R^n$上的连续可微函数，约束函数$h_i(w)$是$R^n$上的仿射函数  \n",
    "当目标函数$f(w)$为二次函数且$g_i(w)$是放射函数时，上述凸优化问题成为凸二次规划问题。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 支持向量\n",
    "在线性可分的情况下，训练数据集中的样本点中与分离超平面距离最近的样本点的实例称为支持向量（support vector）。支持向量是是使约束条件成立的点。即\n",
    "$$\n",
    "y_i(w \\cdot x_i+b)-1=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于$y_i=+1$的正例点，支持向量在超平面\n",
    "$$\n",
    "H1:w \\cdot x +b=1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于$y_i=-1$的负例点，支持向量在超平面\n",
    "$$\n",
    "H2:w \\cdot x+b=-1\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H1与H2之间的距离称为**间隔(margin)**，等于$\\frac{2}{||w||}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学习的对偶算法\n",
    "首先构建拉格朗日函数（Lagrange function）。为此，对每一个不等式约束引入拉格朗日乘子，定义拉格朗日函数：\n",
    "$$\n",
    "L(w,b,\\alpha)=\\frac{1}{2}||w||^2-\\sum_{i=1}^N \\alpha_i y_i (w \\cdot x_i+b)+\\sum_{i=1}^N \\alpha_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始问题\n",
    "$$\n",
    "\\min_{w,b} \\max_{\\alpha} L(w,b,\\alpha)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对偶问题\n",
    "$$\n",
    "\\max_{\\alpha} \\min_{w,b} L(w,b,\\alpha)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 线性可分支持向量机学习算法\n",
    "略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 线性支持向量机与软间隔最大化\n",
    "对线性不可分训练数据，引入松弛变量$\\xi_i$，约束条件变为：\n",
    "$$\n",
    "y_i(w \\cdot x_i +b) \\ge 1-\\xi_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标函数变为：\n",
    "$$\n",
    "\\frac{1}{2}||w||^2+C\\sum_{i=1}^N \\xi_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对应凸二次规划\n",
    "$$\n",
    "\\min_{w,b,\\xi} \\frac{1}{2}||w||^2+C\\sum_{i=1}^N \\xi_i \\\\\n",
    "s.t. \\quad y_i(w \\cdot x_i+b) \\ge 1- \\xi_i, \\quad i=1,2,\\ldots,N\\\\\n",
    "\\xi_i \\ge 0, \\quad i=1,2,\\ldots,N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以证明$w$的解是唯一的，但b的解不唯一,b的解存在于一个区间。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对偶问题是**\n",
    "$$\n",
    "\\max_{\\alpha} \\frac{1}{2}\\sum_{i=1}^N \\sum_{j=1}^N \\alpha_i \\alpha_j y_i y_j (x_i \\cdot x_j) -\\sum_{i=1}^N \\alpha_i \\\\\n",
    "s.t. \\quad \\sum_{i=1}^N \\alpha_i y_i=0 \\\\\n",
    "0 \\le \\alpha_i \\le C, \\quad i=1,2,\\ldots,N\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "S.T.\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
